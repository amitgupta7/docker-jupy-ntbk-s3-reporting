{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import fnmatch\n",
    "import os\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "def loadPrometheusData(root, fileRegex, metricsName, fileAggFunc, fileExtn, aggfunction):\n",
    "    print(\"processing \"+fileRegex+metricsName+'-'+fileAggFunc+'*'+fileExtn)\n",
    "    df1 = loadDataFrameFromFileRegex(root, fileRegex+metricsName+'-'+fileAggFunc+'*'+fileExtn, metrics=metricsName+'_'+fileAggFunc)\n",
    "    if(metricsName == 'task_queue_length'):\n",
    "        df1.loc[df1['metrics_name'].str.contains('securiti-appliance-downloader-tasks-queue', regex=False), 'metrics'] = 'taskq_'+fileAggFunc\n",
    "        df1.loc[df1['metrics_name'].str.contains('t-appliance-downloader-tasks-queue', regex=False), 'metrics'] = 'downloadq_'+fileAggFunc\n",
    "        df1.loc[df1['metrics_name'].str.contains('securiti-appliance-linker', regex=False), 'metrics'] = 'linkerq_'+fileAggFunc\n",
    "\n",
    "    if(metricsName == 'infra_access_latency'):\n",
    "        df1.loc[df1['metrics_name'].str.contains('appliance_es_access_latency', regex=False), 'metrics'] = 'esLatency_'+fileAggFunc\n",
    "        df1.loc[df1['metrics_name'].str.contains('appliance_postgres_access_latency', regex=False), 'metrics'] = 'pgLatency_'+fileAggFunc\n",
    "        df1.loc[df1['metrics_name'].str.contains('appliance_redis_access_latency', regex=False), 'metrics'] = 'redisLatency_'+fileAggFunc\n",
    "\n",
    "    df1['node_ip']=df1['node_ip'].fillna(\"master\")\n",
    "    df1 = df1.groupby(['appliance_id','ts', 'node_ip', 'metrics']).agg(value=('value', aggfunction)).reset_index()   \n",
    "    df1['ts']=pd.to_datetime(df1['ts'],unit='s')\n",
    "    return df1[['appliance_id','ts', 'node_ip', 'metrics', 'value']] \n",
    "\n",
    "def loadDataFrameFromFileRegex(root, regex, **kwargs):\n",
    "    metrics = kwargs.get('metrics', None)\n",
    "    df_arr = []\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, regex) and os.path.getsize(os.path.join(path, name)) > 0:\n",
    "                # print(os.path.join(path, name))\n",
    "                df = pd.read_csv(os.path.join(path, name))\n",
    "                df.insert(1, 'metrics', metrics)\n",
    "                df_arr.append(df)\n",
    "    if not df_arr:\n",
    "        warnings.warn(\"No matching file found in \"+root+\" for regex: \"+regex+\". Empty dataframe will be returned.\" )\n",
    "        return pd.DataFrame()    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning)      \n",
    "        return pd.concat(df_arr, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'dataDir'\n",
    "filePrefix = 'securiti_appliance_'\n",
    "fileExtn = '.csv'\n",
    "\n",
    "# metricsArr = ['infra_access_latency']\n",
    "metricsArr = ['cpu_used', 'download_workers_count', 'memory_used', 'task_queue_length']\n",
    "#'infra_access_latency', 'pod_cpu_usage', 'pod_memory_usage',\n",
    "df_arr = []\n",
    "for metricsName in metricsArr:\n",
    "    for fileAggFunc in ['max', 'avg']:\n",
    "        aggfunction = 'mean'\n",
    "        if(fileAggFunc == 'max'):\n",
    "            aggfunction = 'max'\n",
    "        df_tmp = loadPrometheusData(root, filePrefix, metricsName, fileAggFunc, fileExtn, aggfunction)\n",
    "        df_arr.append(df_tmp)\n",
    "\n",
    "df = pd.concat(df_arr, ignore_index=True)\n",
    "\n",
    "print(\"loading Unstrctured Data from file\")\n",
    "df9 = loadDataFrameFromFileRegex(root, 'UNSTRUCTURED-*.csv', metrics='dataScanned')\n",
    "df9.rename(columns={'pod':'appliance_id'}, inplace=True)\n",
    "df9['node_ip']=\"master\"\n",
    "df9=df9.groupby(['appliance_id', 'ts', 'node_ip']).agg(\\\n",
    "    dataScanned=('dataScannedInGB', 'sum'), \\\n",
    "    scanTime=('processingTimeinHrs', 'sum'), \\\n",
    "    numFilesScanned=('numberOfFilesScanned', 'sum'), \\\n",
    "    scannerIdleTime=('IdleTimeInHrs', 'sum'), \\\n",
    "    uniqPodCount=('uniqPodCount', 'max')).reset_index()\n",
    "df9['ts']=pd.to_datetime(df9['ts'],unit='ms')\n",
    "df9['avgFileSizeInMB']=df9['dataScanned']*1000/df9['numFilesScanned']\n",
    "df9 = pd.melt(df9, id_vars=['appliance_id','ts', 'node_ip'], var_name='metrics', value_name='value')\n",
    "df = pd.concat([df,df9], ignore_index=True)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromDt = '2024-08-04'\n",
    "toDt = '2024-08-19'\n",
    "dfds = df[(df['metrics'] == 'dataScanned') & (df['ts'] >= fromDt) & (df['ts'] <= toDt) ]\n",
    "dfds = dfds.groupby('appliance_id').agg(value=('value', 'sum')).reset_index().sort_values('value', ascending=False)\n",
    "print(dfds.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliance_id = '0af83074-d88b-4990-b033-92f28b161d2c'\n",
    "fromDt = '2024-08-05'\n",
    "toDt = '2024-08-07'\n",
    "dfp = df[(df['appliance_id'] == appliance_id) & (df['ts'] >= fromDt) & (df['ts'] <= toDt) ]\n",
    "fig = px.line(dfp, x=\"ts\", y=\"value\", color='node_ip', facet_row='metrics', height=7000, facet_row_spacing=0.005, \\\n",
    "                            category_orders={\"metrics\": [\"dataScanned\", \"scanTime\"]})\n",
    "fig = fig.update_yaxes(matches=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliance_id = '37286f5a-9f8d-4f05-829a-2e9a8f25c5e4'\n",
    "fromDt = '2024-08-04'\n",
    "toDt = '2024-08-06'\n",
    "dfp = df[(df['appliance_id'] == appliance_id) & (df['ts'] >= fromDt) & (df['ts'] <= toDt) ]\n",
    "dfc = df.pivot_table(index=['appliance_id','ts'], columns='metrics', values='value', aggfunc='max').reset_index()\n",
    "dfc.drop('appliance_id', axis=1, inplace=True)\n",
    "dfc = dfc.corr()\n",
    "fig1 = px.imshow(dfc, text_auto=True, height=1000)\n",
    "fig1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
